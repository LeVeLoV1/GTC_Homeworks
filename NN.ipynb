{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "handsModule = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x17</th>\n",
       "      <th>y17</th>\n",
       "      <th>x18</th>\n",
       "      <th>y18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>2</td>\n",
       "      <td>0.198417</td>\n",
       "      <td>0.557235</td>\n",
       "      <td>0.217409</td>\n",
       "      <td>0.662339</td>\n",
       "      <td>0.268550</td>\n",
       "      <td>0.734442</td>\n",
       "      <td>0.295123</td>\n",
       "      <td>0.796152</td>\n",
       "      <td>0.307173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262487</td>\n",
       "      <td>0.566554</td>\n",
       "      <td>0.308981</td>\n",
       "      <td>0.464506</td>\n",
       "      <td>0.274572</td>\n",
       "      <td>0.508587</td>\n",
       "      <td>0.249077</td>\n",
       "      <td>0.521550</td>\n",
       "      <td>0.257909</td>\n",
       "      <td>0.507398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>3</td>\n",
       "      <td>0.213529</td>\n",
       "      <td>0.576731</td>\n",
       "      <td>0.257309</td>\n",
       "      <td>0.575272</td>\n",
       "      <td>0.302075</td>\n",
       "      <td>0.540928</td>\n",
       "      <td>0.325771</td>\n",
       "      <td>0.495553</td>\n",
       "      <td>0.311015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259843</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.216476</td>\n",
       "      <td>0.436709</td>\n",
       "      <td>0.223121</td>\n",
       "      <td>0.381009</td>\n",
       "      <td>0.229489</td>\n",
       "      <td>0.352547</td>\n",
       "      <td>0.232076</td>\n",
       "      <td>0.320278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>5</td>\n",
       "      <td>0.140430</td>\n",
       "      <td>0.703924</td>\n",
       "      <td>0.209503</td>\n",
       "      <td>0.696566</td>\n",
       "      <td>0.273029</td>\n",
       "      <td>0.629750</td>\n",
       "      <td>0.325201</td>\n",
       "      <td>0.583692</td>\n",
       "      <td>0.377326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.600990</td>\n",
       "      <td>0.084259</td>\n",
       "      <td>0.534127</td>\n",
       "      <td>0.073769</td>\n",
       "      <td>0.512049</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.575196</td>\n",
       "      <td>0.096195</td>\n",
       "      <td>0.591214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>0</td>\n",
       "      <td>0.255297</td>\n",
       "      <td>0.593494</td>\n",
       "      <td>0.289986</td>\n",
       "      <td>0.610349</td>\n",
       "      <td>0.310282</td>\n",
       "      <td>0.639323</td>\n",
       "      <td>0.325730</td>\n",
       "      <td>0.667053</td>\n",
       "      <td>0.336533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207301</td>\n",
       "      <td>0.805734</td>\n",
       "      <td>0.193636</td>\n",
       "      <td>0.629203</td>\n",
       "      <td>0.176530</td>\n",
       "      <td>0.672817</td>\n",
       "      <td>0.176834</td>\n",
       "      <td>0.720038</td>\n",
       "      <td>0.178616</td>\n",
       "      <td>0.768300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>0</td>\n",
       "      <td>0.276524</td>\n",
       "      <td>0.750914</td>\n",
       "      <td>0.375573</td>\n",
       "      <td>0.747577</td>\n",
       "      <td>0.434010</td>\n",
       "      <td>0.643148</td>\n",
       "      <td>0.453828</td>\n",
       "      <td>0.529085</td>\n",
       "      <td>0.492041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264902</td>\n",
       "      <td>0.145801</td>\n",
       "      <td>0.202373</td>\n",
       "      <td>0.522698</td>\n",
       "      <td>0.201782</td>\n",
       "      <td>0.391771</td>\n",
       "      <td>0.204075</td>\n",
       "      <td>0.316772</td>\n",
       "      <td>0.206312</td>\n",
       "      <td>0.237854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>1</td>\n",
       "      <td>0.215314</td>\n",
       "      <td>0.770532</td>\n",
       "      <td>0.230555</td>\n",
       "      <td>0.682660</td>\n",
       "      <td>0.266249</td>\n",
       "      <td>0.613618</td>\n",
       "      <td>0.285453</td>\n",
       "      <td>0.560318</td>\n",
       "      <td>0.282030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321920</td>\n",
       "      <td>0.769120</td>\n",
       "      <td>0.301699</td>\n",
       "      <td>0.840366</td>\n",
       "      <td>0.353982</td>\n",
       "      <td>0.816874</td>\n",
       "      <td>0.335439</td>\n",
       "      <td>0.806793</td>\n",
       "      <td>0.314065</td>\n",
       "      <td>0.809248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>0</td>\n",
       "      <td>0.201892</td>\n",
       "      <td>0.508687</td>\n",
       "      <td>0.251272</td>\n",
       "      <td>0.489458</td>\n",
       "      <td>0.276723</td>\n",
       "      <td>0.429785</td>\n",
       "      <td>0.284563</td>\n",
       "      <td>0.362938</td>\n",
       "      <td>0.303853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151294</td>\n",
       "      <td>0.146517</td>\n",
       "      <td>0.145439</td>\n",
       "      <td>0.365704</td>\n",
       "      <td>0.136327</td>\n",
       "      <td>0.294515</td>\n",
       "      <td>0.133118</td>\n",
       "      <td>0.252755</td>\n",
       "      <td>0.131906</td>\n",
       "      <td>0.210584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0</td>\n",
       "      <td>0.863741</td>\n",
       "      <td>0.894225</td>\n",
       "      <td>0.836424</td>\n",
       "      <td>0.858505</td>\n",
       "      <td>0.823916</td>\n",
       "      <td>0.819842</td>\n",
       "      <td>0.816522</td>\n",
       "      <td>0.785293</td>\n",
       "      <td>0.808597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799144</td>\n",
       "      <td>0.735372</td>\n",
       "      <td>0.846377</td>\n",
       "      <td>0.785367</td>\n",
       "      <td>0.830712</td>\n",
       "      <td>0.755107</td>\n",
       "      <td>0.814353</td>\n",
       "      <td>0.744896</td>\n",
       "      <td>0.802527</td>\n",
       "      <td>0.742186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6784</th>\n",
       "      <td>1</td>\n",
       "      <td>0.267921</td>\n",
       "      <td>0.483193</td>\n",
       "      <td>0.280687</td>\n",
       "      <td>0.404953</td>\n",
       "      <td>0.316910</td>\n",
       "      <td>0.316777</td>\n",
       "      <td>0.327456</td>\n",
       "      <td>0.238351</td>\n",
       "      <td>0.310118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365918</td>\n",
       "      <td>0.464608</td>\n",
       "      <td>0.330984</td>\n",
       "      <td>0.499688</td>\n",
       "      <td>0.405601</td>\n",
       "      <td>0.521907</td>\n",
       "      <td>0.380963</td>\n",
       "      <td>0.527025</td>\n",
       "      <td>0.357577</td>\n",
       "      <td>0.518265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5594</th>\n",
       "      <td>4</td>\n",
       "      <td>0.255080</td>\n",
       "      <td>0.490045</td>\n",
       "      <td>0.327162</td>\n",
       "      <td>0.484606</td>\n",
       "      <td>0.393192</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.422839</td>\n",
       "      <td>0.357183</td>\n",
       "      <td>0.410431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278976</td>\n",
       "      <td>0.380373</td>\n",
       "      <td>0.230520</td>\n",
       "      <td>0.325553</td>\n",
       "      <td>0.258109</td>\n",
       "      <td>0.281145</td>\n",
       "      <td>0.261935</td>\n",
       "      <td>0.350071</td>\n",
       "      <td>0.248899</td>\n",
       "      <td>0.372448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7568 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class        x1        y1        x2        y2        x3        y3  \\\n",
       "5188      2  0.198417  0.557235  0.217409  0.662339  0.268550  0.734442   \n",
       "4746      3  0.213529  0.576731  0.257309  0.575272  0.302075  0.540928   \n",
       "6399      5  0.140430  0.703924  0.209503  0.696566  0.273029  0.629750   \n",
       "4001      0  0.255297  0.593494  0.289986  0.610349  0.310282  0.639323   \n",
       "5983      0  0.276524  0.750914  0.375573  0.747577  0.434010  0.643148   \n",
       "...     ...       ...       ...       ...       ...       ...       ...   \n",
       "4497      1  0.215314  0.770532  0.230555  0.682660  0.266249  0.613618   \n",
       "2466      0  0.201892  0.508687  0.251272  0.489458  0.276723  0.429785   \n",
       "797       0  0.863741  0.894225  0.836424  0.858505  0.823916  0.819842   \n",
       "6784      1  0.267921  0.483193  0.280687  0.404953  0.316910  0.316777   \n",
       "5594      4  0.255080  0.490045  0.327162  0.484606  0.393192  0.433962   \n",
       "\n",
       "            x4        y4        x5  ...       x17       y17       x18  \\\n",
       "5188  0.295123  0.796152  0.307173  ...  0.262487  0.566554  0.308981   \n",
       "4746  0.325771  0.495553  0.311015  ...  0.259843  0.290698  0.216476   \n",
       "6399  0.325201  0.583692  0.377326  ...  0.137300  0.600990  0.084259   \n",
       "4001  0.325730  0.667053  0.336533  ...  0.207301  0.805734  0.193636   \n",
       "5983  0.453828  0.529085  0.492041  ...  0.264902  0.145801  0.202373   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4497  0.285453  0.560318  0.282030  ...  0.321920  0.769120  0.301699   \n",
       "2466  0.284563  0.362938  0.303853  ...  0.151294  0.146517  0.145439   \n",
       "797   0.816522  0.785293  0.808597  ...  0.799144  0.735372  0.846377   \n",
       "6784  0.327456  0.238351  0.310118  ...  0.365918  0.464608  0.330984   \n",
       "5594  0.422839  0.357183  0.410431  ...  0.278976  0.380373  0.230520   \n",
       "\n",
       "           y18       x19       y19       x20       y20       x21       y21  \n",
       "5188  0.464506  0.274572  0.508587  0.249077  0.521550  0.257909  0.507398  \n",
       "4746  0.436709  0.223121  0.381009  0.229489  0.352547  0.232076  0.320278  \n",
       "6399  0.534127  0.073769  0.512049  0.088571  0.575196  0.096195  0.591214  \n",
       "4001  0.629203  0.176530  0.672817  0.176834  0.720038  0.178616  0.768300  \n",
       "5983  0.522698  0.201782  0.391771  0.204075  0.316772  0.206312  0.237854  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4497  0.840366  0.353982  0.816874  0.335439  0.806793  0.314065  0.809248  \n",
       "2466  0.365704  0.136327  0.294515  0.133118  0.252755  0.131906  0.210584  \n",
       "797   0.785367  0.830712  0.755107  0.814353  0.744896  0.802527  0.742186  \n",
       "6784  0.499688  0.405601  0.521907  0.380963  0.527025  0.357577  0.518265  \n",
       "5594  0.325553  0.258109  0.281145  0.261935  0.350071  0.248899  0.372448  \n",
       "\n",
       "[7568 rows x 43 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = shuffle(pd.read_csv(\"gestures_data.csv\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data.iloc[:7000,1:].values.tolist()\n",
    "y_train = data.iloc[:7000,0].values.tolist()\n",
    "x_test = data.iloc[7000:,1:].values.tolist()\n",
    "y_test = data.iloc[7000:,0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.Tensor(x_train)\n",
    "y_train = torch.Tensor(y_train).long()\n",
    "x_test = torch.Tensor(x_test)\n",
    "y_test = torch.Tensor(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(42, 32)\n",
    "        self.b1 = nn.BatchNorm1d(32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.b2 = nn.BatchNorm1d(32)\n",
    "        self.fc3 = nn.Linear(32,16)\n",
    "        self.b3 = nn.BatchNorm1d(16)\n",
    "        self.fc4 = nn.Linear(16,6)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.b1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.b2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.b3(x)\n",
    "        x = F.softmax(self.fc4(x), dim = 1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "def train(model, x, y, optimizer, criterion):\n",
    "    model.zero_grad()           # zeroes the gradient buffers of all parameters\n",
    "    output = model(x)           # forward\n",
    "    loss =criterion(output,y)   # calculate the loss\n",
    "    loss.backward()             # back propagation\n",
    "    optimizer.step()            # update gradients\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    train(net, x_train, y_train, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = net(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(544, 568)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plus = 0\n",
    "for i in range(len(result)):\n",
    "    if torch.argmax(result[i]) == y_test[i]:\n",
    "        plus += 1\n",
    "plus, len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(5)\n",
      "tensor(0)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(1)\n",
      "tensor(0)\n",
      "tensor(1)\n",
      "tensor(0)\n",
      "tensor(4)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(1)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with handsModule.Hands(static_image_mode=True, max_num_hands=4, min_detection_confidence=0.8) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "        cv2.flip(image, 1)\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "         \n",
    "        if results.multi_hand_landmarks:\n",
    "            for handLandmarks in results.multi_hand_landmarks:\n",
    "                # process each hand list of landmarks\n",
    "                mp_drawing.draw_landmarks(image, handLandmarks, handsModule.HAND_CONNECTIONS)\n",
    "                data = [[],[0]*42]\n",
    "                for point in handsModule.HandLandmark:\n",
    "                    # process each landmark\n",
    "                    \n",
    "                    # To access the actual list of landmarks of the hand by index, we cannot directly \n",
    "                    # use the handLandmarks variable. We need to access its landmark field instead.\n",
    "                    normalizedLandmark = handLandmarks.landmark[point]\n",
    "                    \n",
    "                    data[0].append(normalizedLandmark.x)\n",
    "                    data[0].append(normalizedLandmark.y)\n",
    "                \n",
    "                d = torch.argmax(net(torch.Tensor(data))[0])\n",
    "                print(d)\n",
    "                \n",
    "                               \n",
    "        cv2.imshow(\"Hand Tracking\", image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {\"palm\": 0, \"thumb up\": 1, \"thumb down\": 2, \"ok\": 3, \"fist\": 4, \"l\": 5}\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
